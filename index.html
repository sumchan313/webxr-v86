<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Immersive Hand Tracking XR</title>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
    #video { display: none; }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline></video>
  <script type="module">
    import * as THREE from 'https://cdn.skypack.dev/three';
    import { VRButton } from 'https://cdn.skypack.dev/three/examples/jsm/webxr/VRButton.js';

    // Scene setup
    const scene = new THREE.Scene();
    scene.background = new THREE.Color('white');
    const camera = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.01, 100);
    camera.position.z = 2;

    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.xr.enabled = true;
    document.body.appendChild(renderer.domElement);
    document.body.appendChild(VRButton.createButton(renderer));

    // Add a cube
    const geometry = new THREE.BoxGeometry(0.2, 0.2, 0.2);
    const material = new THREE.MeshNormalMaterial();
    const cube = new THREE.Mesh(geometry, material);
    scene.add(cube);

    // Animate
    renderer.setAnimationLoop(() => {
      cube.rotation.x += 0.01;
      cube.rotation.y += 0.01;
      renderer.render(scene, camera);
    });

    // Webcam setup for hand tracking
    const video = document.getElementById('video');
    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
      video.srcObject = stream;
    });

    // You can now integrate MediaPipe here to track hands and map gestures to cube movement
    // For full gesture control, you'd use MediaPipe Hands and map index finger position to cube.x/y/z
  </script>
</body>
</html>
