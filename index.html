<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AR + LVR + VR Hand Tracking with Camera Overlay + OBJ</title>
  <style>
    body { margin: 0; overflow: hidden; }
    #enterAR, #enterLVR, #enterARVR {
      position: absolute;
      top: 20px;
      left: 20px;
      z-index: 2;
      padding: 10px 20px;
      font-size: 16px;
      background: black;
      color: white;
      border: none;
      cursor: pointer;
      margin-right: 10px;
    }
    #enterLVR { left: 140px; }
    #enterARVR { left: 260px; }
    #video {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 0;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
      z-index: 1;
    }
  </style>
</head>
<body>
  <button id="enterAR">Enter AR</button>
  <button id="enterLVR">Enter LVR</button>
  <button id="enterARVR">Enter VR</button>
  <video id="video" autoplay playsinline muted></video>

  <script src="https://cdn.jsdelivr.net/npm/three@0.152.2/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.152.2/examples/js/loaders/OBJLoader.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

  <script>
    let cube, renderer, scene, camera;
    let leftCamera, rightCamera;
    let isLVR = false;
    let isARVR = false;
    let t = 0;

    window.addEventListener('DOMContentLoaded', () => {
      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.01, 100);
      camera.position.z = 1;

      renderer = new THREE.WebGLRenderer({ alpha: true });
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.xr.enabled = true;
      renderer.setClearColor(0x000000, 0);
      document.body.appendChild(renderer.domElement);

      cube = new THREE.Mesh(
        new THREE.BoxGeometry(0.2, 0.2, 0.2),
        new THREE.MeshNormalMaterial({ transparent: true, opacity: 0.8 })
      );
      cube.position.set(0, 0.5, -1);
      scene.add(cube);

      const loader = new THREE.OBJLoader();
      loader.load('https://threejs.org/examples/models/obj/male02/male02.obj', obj => {
        obj.scale.set(0.01, 0.01, 0.01);
        obj.position.set(0.5, -0.5, -1);
        scene.add(obj);
      });

      renderer.setAnimationLoop(() => {
        t += 0.01;
        cube.position.y = 0.5 + Math.sin(t) * 0.05;

        if (isLVR) {
          renderStereo();
        } else {
          renderer.render(scene, camera);
        }
      });

      document.getElementById('enterAR').addEventListener('click', async () => {
        if (!navigator.xr) {
          alert('WebXR AR not supported');
          return;
        }

        const supported = await navigator.xr.isSessionSupported('immersive-ar');
        if (!supported) {
          alert('AR session not supported on this device/browser');
          return;
        }

        try {
          const session = await navigator.xr.requestSession('immersive-ar', {
            requiredFeatures: ['local-floor', 'hit-test']
          });

          renderer.xr.setSession(session);

          const refSpace = await session.requestReferenceSpace('local-floor');
          const viewerSpace = await session.requestReferenceSpace('viewer');
          const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

          renderer.setAnimationLoop((timestamp, frame) => {
            if (frame) {
              const hitTestResults = frame.getHitTestResults(hitTestSource);
              if (hitTestResults.length > 0) {
                const hit = hitTestResults[0];
                const pose = hit.getPose(refSpace);
                if (pose) {
                  cube.position.set(
                    pose.transform.position.x,
                    pose.transform.position.y,
                    pose.transform.position.z
                  );
                }
              }
            }
            renderer.render(scene, camera);
          });
        } catch (err) {
          console.error('AR session failed:', err);
        }
      });

      document.getElementById('enterLVR').addEventListener('click', () => {
        isLVR = true;
        leftCamera = new THREE.PerspectiveCamera(70, window.innerWidth / 2 / window.innerHeight, 0.01, 100);
        rightCamera = new THREE.PerspectiveCamera(70, window.innerWidth / 2 / window.innerHeight, 0.01, 100);
        leftCamera.position.set(-0.03, 0, 1);
        rightCamera.position.set(0.03, 0, 1);
      });

      document.getElementById('enterARVR').addEventListener('click', async () => {
        isARVR = true;
        scene.background = null;
        renderer.setClearColor(0x000000, 0);

        if (navigator.xr) {
          try {
            const session = await navigator.xr.requestSession('immersive-vr', {
              requiredFeatures: ['local-floor']
            });
            renderer.xr.setSession(session);
          } catch (err) {
            console.error('VR session failed:', err);
          }
        } else {
          alert('WebXR VR not supported');
        }
      });

      function renderStereo() {
        renderer.setScissorTest(true);

        renderer.setViewport(0, 0, window.innerWidth / 2, window.innerHeight);
        renderer.setScissor(0, 0, window.innerWidth / 2, window.innerHeight);
        renderer.render(scene, leftCamera);

        renderer.setViewport(window.innerWidth / 2, 0, window.innerWidth / 2, window.innerHeight);
        renderer.setScissor(window.innerWidth / 2, 0, window.innerWidth / 2, window.innerHeight);
        renderer.render(scene, rightCamera);

        renderer.setScissorTest(false);
      }

      const video = document.getElementById('video');
      navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: { ideal: "environment" },
          width: { ideal: 1920 },
          height: { ideal: 1080 }
        }
      }).then(stream => {
        video.srcObject = stream;
      }).catch(err => {
        console.error('Wide-view camera access failed:', err);
      });

      const hands = new Hands({
        locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
      });

      hands.setOptions({
        maxNumHands: 1,
        modelComplexity: 1,
        minDetectionConfidence: 0.7,
        minTrackingConfidence: 0.7
      });

      hands.onResults(results => {
        if (results.multiHandLandmarks.length > 0) {
          const landmarks = results.multiHandLandmarks[0];
          const indexTip = landmarks[8];
          const thumbTip = landmarks[4];

          const x = (indexTip.x - 0.5) * 4;
          const y = -(indexTip.y - 0.5) * 3;
          cube.position.x = x;
          cube.position.y = 0.5 + Math.sin(t) * 0.05 + y * 0.2;

          const dx = indexTip.x - thumbTip.x;
          const dy = indexTip.y - thumbTip.y;
          const distance = Math.sqrt(dx * dx + dy * dy);
          cube.scale.set(distance < 0.05 ? 1.5 : 1, distance < 0.05 ? 1.5 : 1, distance < 0.05 ? 1.5 : 1);
        }
      });

      const cameraFeed = new Camera(video, {
        onFrame: async () => {
          await hands.send({ image: video });
        },
        width: 640,
        height: 480
      });
      cameraFeed.start();
    });
  </script>
</body>
</html>
